transfer:
  # Models to test transferability between
  # Using same model at different layers to demonstrate transferability
  models:
    - name: "gemma-2-2b-l20"
      model_path: "google/gemma-2-2b-it"
      layer: 20
    - name: "gemma-2-2b-l10"
      model_path: "google/gemma-2-2b-it"
      layer: 10
  
  # Concept configuration
  concept_path: "axbench/data/gemma-2-2b_20-gemmascope-res-16k.json"
  total_concepts: 50
  train_concepts: 40
  test_concepts: 10 
  # Data generation settings - using existing pre-generated data
  data_dir: "axbench/concept500/prod_2b_l20_v1/generate"
  
  # Transfer methods to test
  transfer_methods:
    - "identity"      # Direct transfer (no adaptation)
    - "linear"        # Linear transformation
    - "mlp"           # Non-linear MLP
  
  # Linear transfer settings
  linear:
    learning_rate: 0.001
    num_epochs: 100
    batch_size: 32
  
  # MLP transfer settings
  mlp:
    hidden_dims: [512, 256]
    learning_rate: 0.001
    num_epochs: 100
    batch_size: 32
    activation: "relu"
  
  # Evaluation settings
  evaluation:
    steering_datasets: ["AlpacaEval"]
    steering_factors: [0.5, 1.0, 1.5, 2.0, 2.5, 3.0]
    num_examples: 20
    batch_size: 8
    output_length: 128
    master_data_dir: "axbench/data"
    # Skip LM judge evaluation (no OpenAI needed)
    use_lm_judge: false
  
  # Output directories
  output:
    vectors_dir: "axbench/transferability/results_50/vectors"
    transfer_models_dir: "axbench/transferability/results_50/transfer_models"
    evaluation_dir: "axbench/transferability/results_50/evaluation"
    analysis_dir: "axbench/transferability/results/analysis"
  
  # Random seed for reproducibility
  seed: 42
